{'cf': 'ri', 'emb': {'u': 'mlp', 'i': 'mat'}, 'ifc': 'min', 'pred': 'h'}
train_epoch: 1001, loss: 0.0810, recall20: 0.0000 recall10: 0.0000 [10.8669]
train_epoch: 1002, loss: 0.0645, recall20: 0.0000 recall10: 0.0000 [10.8831]
train_epoch: 1003, loss: 0.0611, recall20: 0.0000 recall10: 0.0000 [10.8931]
train_epoch: 1004, loss: 0.0554, recall20: 0.0000 recall10: 0.0000 [10.9030]
train_epoch: 1005, loss: 0.0491, recall20: 0.0000 recall10: 0.0000 [10.9139]
train_epoch: 1006, loss: 0.0483, recall20: 0.0000 recall10: 0.0000 [10.9242]
train_epoch: 1007, loss: 0.0440, recall20: 0.0000 recall10: 0.0000 [10.9339]
train_epoch: 1008, loss: 0.0433, recall20: 0.0000 recall10: 0.0000 [10.9452]
train_epoch: 1009, loss: 0.0409, recall20: 0.0000 recall10: 0.0000 [10.9627]
train_epoch: 1010, loss: 0.0377, recall20: 0.0000 recall10: 0.0000 [10.9735]
train_epoch: 1011, loss: 0.0373, recall20: 0.0000 recall10: 0.0000 [10.9822]
train_epoch: 1012, loss: 0.0356, recall20: 0.0000 recall10: 0.0000 [10.9918]
train_epoch: 1013, loss: 0.0337, recall20: 0.0000 recall10: 0.0000 [11.0006]
train_epoch: 1014, loss: 0.0321, recall20: 0.0000 recall10: 0.0000 [11.0093]
train_epoch: 1015, loss: 0.0321, recall20: 0.1394 recall10: 0.0807 [11.0732]
{'cf': 'ri', 'emb': {'u': 'mlp', 'i': 'mat'}, 'ifc': 'min', 'pred': 'h'}
train_epoch: 1001, loss: 0.0810, recall20: 0.0000 recall10: 0.0000 [84.9320]
train_epoch: 1002, loss: 0.0645, recall20: 0.0000 recall10: 0.0000 [85.0376]
train_epoch: 1003, loss: 0.0611, recall20: 0.0000 recall10: 0.0000 [85.1323]
train_epoch: 1004, loss: 0.0554, recall20: 0.0000 recall10: 0.0000 [85.2336]
train_epoch: 1005, loss: 0.0491, recall20: 0.0000 recall10: 0.0000 [85.3314]
train_epoch: 1006, loss: 0.0483, recall20: 0.0000 recall10: 0.0000 [85.4050]
train_epoch: 1007, loss: 0.0440, recall20: 0.0000 recall10: 0.0000 [85.4960]
train_epoch: 1008, loss: 0.0433, recall20: 0.0000 recall10: 0.0000 [85.5982]
train_epoch: 1009, loss: 0.0409, recall20: 0.0000 recall10: 0.0000 [85.7004]
train_epoch: 1010, loss: 0.0377, recall20: 0.0000 recall10: 0.0000 [85.7981]
train_epoch: 1011, loss: 0.0373, recall20: 0.0000 recall10: 0.0000 [85.9010]
train_epoch: 1012, loss: 0.0356, recall20: 0.0000 recall10: 0.0000 [86.0042]
train_epoch: 1013, loss: 0.0337, recall20: 0.0000 recall10: 0.0000 [86.1048]
train_epoch: 1014, loss: 0.0321, recall20: 0.0000 recall10: 0.0000 [86.1977]
train_epoch: 1015, loss: 0.0321, recall20: 0.1394 recall10: 0.0807 [86.3907]
