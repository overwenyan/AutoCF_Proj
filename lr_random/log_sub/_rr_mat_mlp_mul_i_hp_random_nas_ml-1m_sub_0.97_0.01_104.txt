{'cf': 'rr', 'emb': {'u': 'mat', 'i': 'mlp'}, 'ifc': 'mul', 'pred': 'i'}
train_epoch: 1001, loss: 0.5838, recall20: 0.0000 recall10: 0.0000 [24.4909]
train_epoch: 1002, loss: 0.5838, recall20: 0.0000 recall10: 0.0000 [24.5192]
train_epoch: 1003, loss: 0.5838, recall20: 0.0000 recall10: 0.0000 [24.5463]
train_epoch: 1004, loss: 0.5838, recall20: 0.0000 recall10: 0.0000 [24.5723]
train_epoch: 1005, loss: 0.5838, recall20: 0.0000 recall10: 0.0000 [24.5993]
train_epoch: 1006, loss: 0.5838, recall20: 0.0000 recall10: 0.0000 [24.6259]
train_epoch: 1007, loss: 0.5838, recall20: 0.0000 recall10: 0.0000 [24.6520]
train_epoch: 1008, loss: 0.5838, recall20: 0.0000 recall10: 0.0000 [24.6791]
train_epoch: 1009, loss: 0.5838, recall20: 0.0000 recall10: 0.0000 [24.7060]
train_epoch: 1010, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [24.7356]
train_epoch: 1011, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [24.7619]
train_epoch: 1012, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [24.7892]
train_epoch: 1013, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [24.8164]
train_epoch: 1014, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [24.8436]
train_epoch: 1015, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [24.8706]
train_epoch: 1016, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [24.8978]
train_epoch: 1017, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [24.9238]
train_epoch: 1018, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [24.9509]
train_epoch: 1019, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [24.9776]
train_epoch: 1020, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [25.0050]
train_epoch: 1021, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [25.0315]
train_epoch: 1022, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [25.0577]
train_epoch: 1023, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [25.0872]
train_epoch: 1024, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [25.1158]
train_epoch: 1025, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [25.1439]
train_epoch: 1026, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [25.1696]
train_epoch: 1027, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [25.1981]
train_epoch: 1028, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [25.2245]
train_epoch: 1029, loss: 0.5837, recall20: 0.0000 recall10: 0.0000 [25.2499]
train_epoch: 1030, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.2760]
train_epoch: 1031, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.3029]
train_epoch: 1032, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.3285]
train_epoch: 1033, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.3561]
train_epoch: 1034, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.3846]
train_epoch: 1035, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.4124]
train_epoch: 1036, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.4389]
train_epoch: 1037, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.4682]
train_epoch: 1038, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.4954]
train_epoch: 1039, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.5205]
train_epoch: 1040, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.5489]
train_epoch: 1041, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.5752]
train_epoch: 1042, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.6020]
train_epoch: 1043, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.6282]
train_epoch: 1044, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.6529]
train_epoch: 1045, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.6788]
train_epoch: 1046, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.7050]
train_epoch: 1047, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.7315]
train_epoch: 1048, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.7579]
train_epoch: 1049, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.7861]
train_epoch: 1050, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.8130]
train_epoch: 1051, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.8399]
train_epoch: 1052, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.8673]
train_epoch: 1053, loss: 0.5836, recall20: 0.0000 recall10: 0.0000 [25.8937]
train_epoch: 1054, loss: 0.5835, recall20: 0.0000 recall10: 0.0000 [25.9198]
train_epoch: 1055, loss: 0.5839, recall20: 0.0106 recall10: 0.0065 [26.3416]
