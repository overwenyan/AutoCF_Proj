{'cf': 'rr', 'emb': {'u': 'mlp', 'i': 'mat'}, 'ifc': 'max', 'pred': 'mlp'}
train_epoch: 1001, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.4170]
train_epoch: 1002, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.4376]
train_epoch: 1003, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.4523]
train_epoch: 1004, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.4659]
train_epoch: 1005, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.4800]
train_epoch: 1006, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.4928]
train_epoch: 1007, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.5058]
train_epoch: 1008, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.5186]
train_epoch: 1009, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.5325]
train_epoch: 1010, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.5454]
train_epoch: 1011, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.5582]
train_epoch: 1012, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.5719]
train_epoch: 1013, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.5849]
train_epoch: 1014, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.5980]
train_epoch: 1015, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.6107]
train_epoch: 1016, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.6235]
train_epoch: 1017, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.6364]
train_epoch: 1018, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.6492]
train_epoch: 1019, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.6622]
train_epoch: 1020, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.6748]
train_epoch: 1021, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.6886]
train_epoch: 1022, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.7017]
train_epoch: 1023, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.7149]
train_epoch: 1024, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.7286]
train_epoch: 1025, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.7418]
train_epoch: 1026, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.7545]
train_epoch: 1027, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.7680]
train_epoch: 1028, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.7807]
train_epoch: 1029, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.7938]
train_epoch: 1030, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.8067]
train_epoch: 1031, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.8196]
train_epoch: 1032, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.8325]
train_epoch: 1033, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.8451]
train_epoch: 1034, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.8574]
train_epoch: 1035, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.8700]
train_epoch: 1036, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.8834]
train_epoch: 1037, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.8967]
train_epoch: 1038, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.9107]
train_epoch: 1039, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.9259]
train_epoch: 1040, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.9390]
train_epoch: 1041, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.9516]
train_epoch: 1042, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.9642]
train_epoch: 1043, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.9765]
train_epoch: 1044, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [11.9887]
train_epoch: 1045, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.0028]
train_epoch: 1046, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.0159]
train_epoch: 1047, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.0287]
train_epoch: 1048, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.0414]
train_epoch: 1049, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.0557]
train_epoch: 1050, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.0696]
train_epoch: 1051, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.0816]
train_epoch: 1052, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.0942]
train_epoch: 1053, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.1074]
train_epoch: 1054, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.1200]
train_epoch: 1055, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.1330]
train_epoch: 1056, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.1505]
train_epoch: 1057, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.1632]
train_epoch: 1058, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.1754]
train_epoch: 1059, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.1877]
train_epoch: 1060, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.1999]
train_epoch: 1061, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.2130]
train_epoch: 1062, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.2269]
train_epoch: 1063, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.2406]
train_epoch: 1064, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.2539]
train_epoch: 1065, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.2671]
train_epoch: 1066, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.2820]
train_epoch: 1067, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.2956]
train_epoch: 1068, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.3091]
train_epoch: 1069, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.3219]
train_epoch: 1070, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.3345]
train_epoch: 1071, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.3502]
train_epoch: 1072, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.3641]
train_epoch: 1073, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.3805]
train_epoch: 1074, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.3944]
train_epoch: 1075, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.4075]
train_epoch: 1076, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.4209]
train_epoch: 1077, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.4336]
train_epoch: 1078, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.4462]
train_epoch: 1079, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.4595]
train_epoch: 1080, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.4736]
train_epoch: 1081, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.4870]
train_epoch: 1082, loss: 0.0002, recall20: 0.0000 recall10: 0.0000 [12.5000]
train_epoch: 1083, loss: 0.0002, recall20: 0.1490 recall10: 0.0780 [12.5548]
